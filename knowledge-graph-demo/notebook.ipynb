{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Powered Consultancy Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Configuration\n",
    "2. Helper Functions\n",
    "3. Prompts\n",
    "4. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "#openai.api_type = \"azure\"\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "#openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai_deployment = \"chat-gpt35\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from openai import OpenAI\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n  model=\"gpt-3.5-turbo\",\\n  messages=[\\n    {\"role\": \"system\", \"content\": \"You are a stand up comedian from New York with a past as a Uber Eats delivery rider. You were nearly killed in an accident with a tourist on times square.\"},\\n    {\"role\": \"user\", \"content\": \"Tell a joke that involves the funeral of the tourist.\"}\\n  ]\\n)\\n\\nprint(completion.choices[0].message) '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a stand up comedian from New York with a past as a Uber Eats delivery rider. You were nearly killed in an accident with a tourist on times square.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a joke that involves the funeral of the tourist.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the OpenAI API\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        engine=openai_deployment,\n",
    "        max_tokens=15000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    sleep(8)\n",
    "    return nlp_results\n",
    "\n",
    "\n",
    "# Function to take folder of files and a prompt template, and return a json-object of all the entities and relationships\n",
    "def extract_entities_relationships(folder, prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"./data/{folder}/*\")\n",
    "    system_msg = \"You are a helpful IT-project and account management expert who extracts information from documents.\"\n",
    "    print(f\"Running pipeline for {len(files)} files in {folder} folder\")\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"Extracting entities and relationships for {file}\")\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                text = f.read().rstrip()\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_gpt(prompt, system_msg=system_msg)\n",
    "                results.append(json.loads(result))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    end = timer()\n",
    "    print(f\"Pipeline completed in {end-start} seconds\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to take a json-object of entitites and relationships and generate cypher query for creating those entities\n",
    "def generate_cypher(json_obj):\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    e_label_map = {}\n",
    "\n",
    "    # loop through our json object\n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "        for entity in obj[\"entities\"]:\n",
    "            label = entity[\"label\"]\n",
    "            id = entity[\"id\"]\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            e_statements.append(cypher)\n",
    "            e_label_map[id] = label\n",
    "\n",
    "        for rs in obj[\"relationships\"]:\n",
    "            src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "            src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "            src_label = e_label_map[src_id]\n",
    "            tgt_label = e_label_map[tgt_id]\n",
    "\n",
    "            cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "            r_statements.append(cypher)\n",
    "\n",
    "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
    "\n",
    "    return e_statements + r_statements\n",
    "\n",
    "\n",
    "# Final function to bring all the steps together\n",
    "def ingestion_pipeline(folders):\n",
    "    # Extrating the entites and relationships from each folder, append into one json_object\n",
    "    entities_relationships = []\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "\n",
    "    # Generate and execute cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for i, stmt in enumerate(cypher_statements):\n",
    "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmt)\n",
    "        except Exception as e:\n",
    "            with open(\"failed_statements.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for processing project briefs\n",
    "project_prompt_template = \"\"\"\n",
    "From the Project Brief below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Project entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the brief; `id` property is the full name of the project, in lowercase, with no capital letters, special characters, spaces or hyphens; Contents of original document must be summarized inside 'summary' property\n",
    "    label:'Technology',id:string,name:string //Technology Entity; `id` property is the name of the technology, in camel-case. Identify as many of the technologies used as possible\n",
    "    label:'Client',id:string,name:string;industry:string //Client that the project was done for; `id` property is the name of the Client, in camel-case; 'industry' is the industry that the client operates in, as mentioned in the project brief.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    project|USES_TECH|technology \n",
    "    project|HAS_CLIENT|client\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Project\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"projectid|USES_TECH|technologyid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing peoples' profiles\n",
    "people_prompt_template = \"\"\"From the list of people below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that the data is about. `id` property is the name of the person, in camel-case. 'name' is the person's name, as spelled in the text.\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the profile; `id` property is the full lowercase name of the project, with no capital letters, special characters, spaces or hyphens.\n",
    "    label:'Technology',id:string,name:string //Technology Entity, as listed in the \"skills\"-section of every person; `id` property is the name of the technology, in camel-case.\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    person|HAS_SKILLS|technology \n",
    "    project|HAS_PEOPLE|person\n",
    "\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":string,\"name\":string}],\n",
    "    \"relationships\": [\"projectid|HAS_PEOPLE|personid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing slack messages\n",
    "\n",
    "slack_prompt_template = \"\"\"\n",
    "From the list of messages below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that sent the message. `id` property is the name of the person, in camel-case; for example, \"michaelClark\", or \"emmaMartinez\"; 'name' is the person's name, as spelled in the text.\n",
    "    label:'SlackMessage',id:string,text:string //The Slack-Message that was sent; 'id' property should be the message id, as spelled in the reference. 'text' property is the text content of the message, as spelled in the reference\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    personid|SENT|slackmessageid\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"SlackMessage\",\"id\":string,\"text\":string}],\n",
    "    \"relationships\": [\"personid|SENT|messageid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 3 files in people_profiles folder\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles1.md\n",
      "Error processing ./data/people_profiles/people-profiles1.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles2.md\n",
      "Error processing ./data/people_profiles/people-profiles2.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/people_profiles/people-profiles3.md\n",
      "Error processing ./data/people_profiles/people-profiles3.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Pipeline completed in 0.0009454000100959092 seconds\n",
      "Running pipeline for 11 files in project_briefs folder\n",
      "Extracting entities and relationships for ./data/project_briefs/GammaTech Smart Logistics Platform on Azure.md\n",
      "Error processing ./data/project_briefs/GammaTech Smart Logistics Platform on Azure.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/GammaTech Autonomous Fleet Management System on Azure.md\n",
      "Error processing ./data/project_briefs/GammaTech Autonomous Fleet Management System on Azure.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/AlphaCorp Supply Chain Optimization Platform.md\n",
      "Error processing ./data/project_briefs/AlphaCorp Supply Chain Optimization Platform.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/DeltaEdu Virtual Classroom Platform on AWS.md\n",
      "Error processing ./data/project_briefs/DeltaEdu Virtual Classroom Platform on AWS.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/DeltaEdu AI-Powered Student Performance Analytics on AWS.md\n",
      "Error processing ./data/project_briefs/DeltaEdu AI-Powered Student Performance Analytics on AWS.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/AlphaCorp Customer Support Chatbot.md\n",
      "Error processing ./data/project_briefs/AlphaCorp Customer Support Chatbot.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/BetaHealth Secure Healthcare Data Analytics Platform on Azure.md\n",
      "Error processing ./data/project_briefs/BetaHealth Secure Healthcare Data Analytics Platform on Azure.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/AlphaCorp AWS-Powered Sales Analytics Dashboard.md\n",
      "Error processing ./data/project_briefs/AlphaCorp AWS-Powered Sales Analytics Dashboard.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/EpsilonFinance Mobile-First Digital Wallet on Google Cloud.md\n",
      "Error processing ./data/project_briefs/EpsilonFinance Mobile-First Digital Wallet on Google Cloud.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/BetaHealth AI-Driven Patient Care Enhancement Platform on Azure.md\n",
      "Error processing ./data/project_briefs/BetaHealth AI-Driven Patient Care Enhancement Platform on Azure.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/project_briefs/BetaHealth Telemedicine Platform on Microsoft Azure.md\n",
      "Error processing ./data/project_briefs/BetaHealth Telemedicine Platform on Microsoft Azure.md: module 'openai' has no attribute 'ChatCompletion'\n",
      "Pipeline completed in 0.0005051010084571317 seconds\n",
      "Running pipeline for 7 files in slack_messages folder\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages5.json\n",
      "Error processing ./data/slack_messages/slack_messages5.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages1.json\n",
      "Error processing ./data/slack_messages/slack_messages1.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages2.json\n",
      "Error processing ./data/slack_messages/slack_messages2.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages7.json\n",
      "Error processing ./data/slack_messages/slack_messages7.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages4.json\n",
      "Error processing ./data/slack_messages/slack_messages4.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages6.json\n",
      "Error processing ./data/slack_messages/slack_messages6.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Extracting entities and relationships for ./data/slack_messages/slack_messages3.json\n",
      "Error processing ./data/slack_messages/slack_messages3.json: module 'openai' has no attribute 'ChatCompletion'\n",
      "Pipeline completed in 0.0004489999992074445 seconds\n"
     ]
    }
   ],
   "source": [
    "folders = {\n",
    "    \"people_profiles\": people_prompt_template,\n",
    "    \"project_briefs\": project_prompt_template,\n",
    "    \"slack_messages\": slack_prompt_template,\n",
    "}\n",
    "\n",
    "ingestion_pipeline(folders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
